---
title: "LBB1"
author: "Reynard Verill"
date: "`r format(Sys.Date(), '%B %e, %Y')`"
output:
  html_document:
    df_print: paged
    highlight: breezedark
    theme: united
    toc: yes
    toc_float:
      collapsed: no
    css: assets/style.css
  pdf_document:
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", out.width = "80%")
options(scipen = 99)
```


<style>
body {
text-align: justify}
</style>

# Objectives

In this project, we will analyze a bank's data set, which was obtained from https://archive.ics.uci.edu/ml/datasets/bank+marketing, and try gain insights regarding the completeness of its data set, along with preparing the data set for further experimentation and prediction using various models.

```{r}
knitr::include_graphics("assets/bank.jpeg")
```

# Libraries and Setup

In this section, we will import the necessary libraries for this project.

```{r cars}
library(tidyverse)
library(dplyr)
library(GGally)
```

# Read Data

Here, we will read the csv data file into our IDE, do further inspection regarding our data, and perform suitable data cleansing for further processing.

```{r pressure, echo=FALSE}
bank <- read.csv("bank/bank.csv", header = TRUE, sep = ";")
```

# Data pre-processing

Here we will perform an integral part of preparing our data into an understandable and complete format for the next step of machine learning.

## Data Inspection

```{r}
glimpse(bank)
```

Input variables:
   # bank client data:
   1 - age (numeric)
   2 - job : type of job (categorical: "admin.","unknown","unemployed","management","housemaid","entrepreneur","student",
                                       "blue-collar","self-employed","retired","technician","services") 
   3 - marital : marital status (categorical: "married","divorced","single"; note: "divorced" means divorced or widowed)
   4 - education (categorical: "unknown","secondary","primary","tertiary")
   5 - default: has credit in default? (binary: "yes","no")
   6 - balance: average yearly balance, in euros (numeric) 
   7 - housing: has housing loan? (binary: "yes","no")
   8 - loan: has personal loan? (binary: "yes","no")
   # related with the last contact of the current campaign:
   9 - contact: contact communication type (categorical: "unknown","telephone","cellular") 
  10 - day: last contact day of the month (numeric)
  11 - month: last contact month of year (categorical: "jan", "feb", "mar", ..., "nov", "dec")
  12 - duration: last contact duration, in seconds (numeric)
   # other attributes:
  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)
  15 - previous: number of contacts performed before this campaign and for this client (numeric)
  16 - poutcome: outcome of the previous marketing campaign (categorical: "unknown","other","failure","success")

Check the dimension of our data frame. The dimension is 4521*17 (4521 rows x 17 columns).
```{r}
dim(bank)
```

Check whether there is any missing value inside our data frame. In the results below, it can be seen that our data is complete and does not require further imputations.
```{r}
colSums(is.na(bank))
```

See the first 6 rows from our data set by using the head function to get a sense of how our actual data looks like.
```{r}
bank %>% head()
```

See the last 6 rows from our data set by using the tail function to get a sense of how our actual data looks like.
```{r}
bank %>% tail()
```

## Data Cleansing

In this section of the report, we will make necessary adjustments to the data set in order to make it feasible for further processing and data exploration.

As can be seen from the data description above which was provided by the source, the columns c("job", "marital", "education", "default", "housing", "loan", "contact", "month", "poutcome", "y") should have had categorical values. However, in the above inspection by using the glimpse function, it can be seen that they are still character data types. Hence, below they are transformed into the form of factors.
```{r}
bank <- bank %>% 
  mutate_at(c("job", "marital", "education", "default", "housing", "loan", "contact", "month", "poutcome", "y"), as.factor)
str(bank)
```

Below, we iterate through each columns to check the levels of each categorical variables for every factor data types in our data set.
```{r}
for (column in names(bank)) {
  if (is.factor(bank[,column])) {
    print(paste(column, ":", sep = " "))
    print(levels(bank[,column]))
  }
}
```

# Data Exploration

In this stage, we will try to extract some valuable insights from our data set by using various methods upon the available variables, while also trying to understand the underlying correlation between some important variables.

Below is a brief summary on each variable of the data set.
```{r}
summary(bank)
```

Here, we perform data aggregation between a particular job and the mean bank balance to try to understand the trend between both variables.
```{r}
aggregate(balance ~ job, bank, mean)
```

In the data aggregation below, we are trying to illustrate the standard deviation of bank balance among each jobs available in our data set. It can be seen that the sd is considerably high, indicating a high variation of balance among each job.
```{r}
aggregate(balance ~ job, bank, sd)
```

Below is a mean bank balance for each marital status.
```{r}
aggregate(balance ~ marital, bank, mean)
```

Distribution of bank balance using box plot:
```{r}
boxplot(bank$balance)
```

See the correlations between each two numerical variables.
```{r}
ggcorr(bank)
```

Below, we can see the data distribution of our target variable, y, which is a factor of two levels.
```{r}
prop.table(table(bank$y))
```

# Insights

With the below code, we try to find the job category with the highest chance of buying the product based on historical data. From this analysis, we manage to see that retired persons are the ones with the highest probability of buying, while blue-collars are the ones with the lowest.
```{r}
job_prob <- bank %>%
  group_by(job) %>% 
  summarise(prob_y = prop.table(table(y))["yes"])
arrange(job_prob, desc(prob_y))
```

In the below analysis, we try to find the mean of a person's bank balance given their last education, history of default, and whether he/she has personal loan.
```{r}
round(xtabs(balance ~ education + default + loan , aggregate(balance ~ education + default + loan, bank, mean)),2)
```


Here, we try to find the probability that a customer would buy the product, given the parameters education, default, and loan.
```{r}
bank_yes <- bank %>% 
  group_by(default, loan, education) %>% 
  summarise(prob_y = prop.table(table(y))["yes"])
arrange(bank_yes, desc(prob_y))
```

As the above summary table shows that a person with previous history of default, no loan, and unknown education has the highest probability of buying (0.5), followed by history of default, no loan, and primary education (0.25), we do further inspection below to understand this seemingly unusual phenomenon.
```{r}
bank %>% filter(default=="yes", loan=="no", education=="primary")
```

```{r}
bank %>% filter(default=="yes", loan=="no", education=="unknown")
```

It turns out that the sample data size (2 rows and 4 rows) are too small for these group, and might not produce any significant insight.

# Conclusion

Based on the above data exploration and analysis, it can be deduced that targeting retirees and students might be the best option as they are the most likely to buy this product. Apart from that, a person with a previous history of default might not be a suitable target, as on average, they usually have a negative balance, which reflects their low purchasing power. Additionally, the bank might also consider targeting individuals with tertiary education background, no loan, and no default history.